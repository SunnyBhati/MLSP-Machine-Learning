{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Weights and bias are [[ 0.0515405   0.04166119 -0.03640807  0.09922397]]\n",
      "The perceptron Converges at iteration number:  122\n",
      "Final weights and the bias are: [[ 0.30670853  0.00057997 -0.00094975 -0.18723104]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from itertools import chain\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import random\n",
    "\n",
    "# Load the concentric.mat file ....\n",
    "M = scipy.io.loadmat('concentric.mat')\n",
    "M = M['X']\n",
    "z = np.sqrt(M[0]**2 + M[1]**2)\n",
    "plt.scatter(M[0],M[1], s=80, c = z, marker=\"o\")\n",
    "plt.show()\n",
    "mat = M.T\n",
    "\n",
    "dist = euclidean_distances(mat, mat)\n",
    "dist  = np.square(dist)\n",
    "\n",
    "# Perform row mean and col mean operations ....\n",
    "d_row_mean = np.mean(dist,axis=1)\n",
    "d_tilda = dist - d_row_mean\n",
    "d_tilda_col_mean = np.mean(d_tilda,axis=0)\n",
    "W = d_tilda - d_tilda_col_mean\n",
    "W = -0.5*W;\n",
    "w_rbf = np.exp(- W / 0.1 )\n",
    "\n",
    "# Generate eigen values and eigen vectors ....\n",
    "eigenval, eigenvec = np.linalg.eig(w_rbf)\n",
    "eval_mat = np.zeros((152,152))\n",
    "np.fill_diagonal(eval_mat,eigenval.real)\n",
    "\n",
    "coord = np.dot(eigenvec,eval_mat)\n",
    "x_axis = coord[:,0]\n",
    "x_axis = x_axis.real\n",
    "y_axis = coord[:,1]\n",
    "y_axis = y_axis.real\n",
    "z_axis = coord[:,2]\n",
    "z_axis = z_axis.real\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax = Axes3D(fig)\n",
    "ax.scatter(x_axis, y_axis, z_axis, c = z_axis,s=20)\n",
    "plt.show()\n",
    "\n",
    "# Generate class variables for both the circles ....\n",
    "class_0 = list(np.zeros((51,)))\n",
    "class_1 = list(np.ones((101,)))\n",
    "cs = list(chain(class_0,class_1))\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax = Axes3D(fig)\n",
    "ax.scatter(x_axis, y_axis, z_axis, c = cs,s=20)\n",
    "plt.show()\n",
    "\n",
    "# prepare the input data with the bias for the perceptron ....\n",
    "bias  = [1] * 152\n",
    "x_y_z = [list(x_axis),list(y_axis),list(z_axis),bias]\n",
    "d_mat = np.array(x_y_z)\n",
    "\n",
    "# Sigmoid and accuracy functions to be used for training ....\n",
    "def activation_function(z):\n",
    "    sigmoid_value = 1 / (1 + np.exp(-z))\n",
    "    return sigmoid_value\n",
    "\n",
    "def activation_function_derivation(z):\n",
    "    value = np.multiply(activation_function(z), (1 - activation_function(z)))\n",
    "    return value\n",
    "\n",
    "def accuracy(cs,pred):\n",
    "    same = 0\n",
    "    for i in range(len(cs)):\n",
    "        if cs[i] == pred[i]:\n",
    "            same = same+1\n",
    "    return same / len(cs)\n",
    "\n",
    "\n",
    "s = np.random.normal(0, 0.1, 4)\n",
    "wt = s.reshape((1, 4))\n",
    "wt_old = wt\n",
    "alpha = 0.025\n",
    "n = d_mat.shape[1]\n",
    "print(\"Initial Weights and bias are\",wt_old)\n",
    "actual_class = np.array(cs)\n",
    "actual_class = actual_class.reshape((1, 152))\n",
    "error = []\n",
    "\n",
    "for i in range(100000):\n",
    "    i += 1\n",
    "    z = np.dot(wt_old, d_mat)\n",
    "    sigmoid_value = activation_function(z)\n",
    "\n",
    "    difference = sigmoid_value - actual_class\n",
    "    error.append(np.sum(abs(difference)))\n",
    "    err = 0.5 * np.dot(difference, difference.T)\n",
    "\n",
    "    delta_1 = np.multiply(difference, activation_function_derivation(z))\n",
    "    delta_2 = alpha * (err) * np.dot(delta_1, d_mat.T)\n",
    "    wt_old = wt_old - delta_2\n",
    "\n",
    "    # Accuracy determination code...\n",
    "    y_cap = [1 if x >= 0.5 else 0 for x in list(sigmoid_value)[0]]\n",
    "    acc = accuracy(cs, y_cap)\n",
    "\n",
    "    if (acc == 1):\n",
    "        print(\"The perceptron Converges at iteration number: \", i)\n",
    "        break\n",
    "\n",
    "print(\"Final weights and the bias are:\", wt_old)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
